{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping the NBA website to follow the games live without your collegues knowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Series 1 of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every now and then I like to follow some sports to distract myself from the usual routine and to get a mental rest from heavy thought processes at work or when developing my personal projects. So in colloquial terms, one may say that I like to procrastinate occasionally. \n",
    "\n",
    "NBA games is one of these distractors that I use to get my mind to relax. Unfortunately for me, it turns out that the games tend to be showcased in the middle of office hours, making it a little bit difficult to follow the games live. Luckily and understanding that we are humans, the company that I work with allow us to access sites like the NBA so we are able to connect with things that interest us having always in mind fullfilling the projects assigned to ourselves.\n",
    "\n",
    "However for some people this may be more restrictive, so been able to get the scores live of a Lakers vs Clippers game while your boss is breathing in your neck may be challenging. Fortunately for us, with a little bit of python and web scrapping magic you can run some scripts to get the latest updated score of the games without people knowing that you are :).\n",
    "\n",
    "In this 3 tutorials I will take through the basics of how to do web scrapping over a Javascript rendered website (In this case the NBA website) to a more extensive review of how to create some code that allow us to retrieve any information to create a database of the results of your favourite team over the season.\n",
    "\n",
    "For this, you will find yourself using python and a popular webscrapper called Selenium to explore and extract any information that you need from any available website. A quick disclaimer here: Always check that the website you are wanting to scrap allows and is ok with you doing so. Also, ideally if a website has an API that you can query and get the information from, it will be much more efficient and practical to use such channel to extract the information rather than scrapping their xml tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to jump straight to the application.... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please click here:   . However, if you are not familiar with how to do some web scrapping and html reading I strongly recommend you to follow along the series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a said before, the idea is for us to cover the basic and build from there so the first thing that you will like to do to be able to follow along (other than having python installed in your machine), is to install and set up selenium in your working space. The best thing you will like to do to be able to, is to follow the instructions of selenium according to your OS and the web browser you regularly use to navigate. Please find all these information here: https://selenium-python.readthedocs.io/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have set up the basics, we can start..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first thing to do is to call the libraries that we will be using for this particular project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"C:/Users/luisa/Documents/GitHub/Web-Spider---Sentiment-Analysis/venv/env/Lib/site-packages\")\n",
    "\n",
    "sys.path.insert(0, \"C:/Users/RojasL/PycharmProjects/untitled3/venv/Lib/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all Selenium relevant modules\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "# Some HTML and display core function for flashy displays ;)\n",
    "from IPython.core.display import display, HTML, Image\n",
    "# Python widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Box, VBox, Label, Layout, HBox\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, what we will like to do is to define the URL that we will like selenium to open and thus extract the information from there. If you find yourself having to fill a form or press some buttons on the website before getting to the actual place from where you want to extract the informatio. Worry not my friend!!, we can do that with selenium too and will show you later how to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_logos = 'https://stats.nba.com/teams/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first exercise we will extract the logos and names of all the NBA team and create a little interactor using python widgets. Then, we shall initialize our selenium web driver (In my case using firefox, howevere you can use any just by changing the driver call a bit i.e. Chrome: driver.Chrome()) and pass the url that we want to query using the get function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver = webdriver.Firefox()\n",
    "driver = webdriver.Chrome('C:/Users/RojasL/Downloads/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will open a web browser that is controllable via python and so you can automate tasks or build different codes to iterate and interact however you would like with the given website. Now, before jumping into the NBA logos we have to understand some of the basics extraction task. How to get an specific element from an html structure.... Imagine we have the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_structure= '''\n",
    "<html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1 id=\"header\"> This is my header</h1>\n",
    "        </div>\n",
    "        <div>\n",
    "            <p id=\"paragraph1\"> This is my paragraph 1</p>\n",
    "            <div>\n",
    "                <p id=\"subparagraph1\"> this is my subparagraph 1</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        <div>\n",
    "            <p id=\"paragraph2\"> This is my paragraph 1</p>\n",
    "            <div>\n",
    "                <p id=\"subparagraph2\"> this is my subparagraph 2</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    </body>      \n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which in a web browser will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "    <head></head>\n",
       "    <body>\n",
       "        <div>\n",
       "            <h1 id=\"header\"> This is my header</h1>\n",
       "        </div>\n",
       "        <div>\n",
       "            <p id=\"paragraph1\"> This is my paragraph 1</p>\n",
       "            <div>\n",
       "                <p id=\"subparagraph1\"> this is my subparagraph 1</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        <div>\n",
       "            <p id=\"paragraph2\"> This is my paragraph 1</p>\n",
       "            <div>\n",
       "                <p id=\"subparagraph2\"> this is my subparagraph 2</p>\n",
       "            </div>\n",
       "        </div>\n",
       "    </body>      \n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(html_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine you would like to extract the content of subparagraph 1. You can use a very handy function call find_elements_by_xpath that allows you to specify the path of a certain element and then extract multiple features of such element (In our case, the content). For that, we pass the html structure to our selenium web driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"data:text/html;charset=utf-8,{0}\".format(html_structure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply our handy function by specifying the path of what we want to extract. Here we can either specify the full path or abreviate its location and it will return us a list with all the elements that satisfy the given description. This is why, we specify that we want to get the elemente [0] from that list and furthermore that we want the text of such element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is my subparagraph 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'this is my subparagraph 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full path\n",
    "display(driver.find_elements_by_xpath(\"html/body/div/div/p[@id = 'subparagraph1']\")[0].text)\n",
    "# Abbreviated version\n",
    "display(driver.find_elements_by_xpath(\"//p[@id = 'subparagraph1']\")[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to extract all the existant subparagraphs and form a dataframe with the contents of all this elements? Easy, use exactly the same function. Just change a bit the searching criteria using contains in the statement criteria and we are all done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is my subparagraph 1\n",
      "this is my subparagraph 2\n"
     ]
    }
   ],
   "source": [
    "# All elementes in the HTML structure that satisfy the criteria\n",
    "list_of_elements = driver.find_elements_by_xpath(\"//p[contains(@id, 'subparagraph')]\")\n",
    "# Printing all the returned elements\n",
    "for i in list_of_elements:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just succesfully scrap our first HTML! hurray!!!. More specifically, we told the selenium driver to extract all the 'p' elements which in its 'id' feature contain the word subparagraph. \n",
    "\n",
    "Reader: Ehem... But you didn't create any dataframe\n",
    "\n",
    "Luis: Oooppsss... True true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is my subparagraph 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is my subparagraph 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    my_query\n",
       "0  this is my subparagraph 1\n",
       "1  this is my subparagraph 2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining it all together in a shorter version\n",
    "pd.DataFrame(data = [i.text for i in driver.find_elements_by_xpath(\"//p[contains(@id, 'subparagraph')]\")], \n",
    "            columns = ['my_query'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move to the real thing. For that, we can have our selenium driver reading the NBA logos URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_logos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have done so, a good approach to identify the items that we want to extract out of the website that we are currently querying is to place the cursor on top of the element and then right click and inspect. Something like this will pop up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data_and_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_both\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m         \u001b[1;34m\"\"\"shortcut for returning metadata with shape information, if defined\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m         \u001b[0mb64_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m         \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(\"C:/Users/luisa/Documents/GitHub/Untitled Folder/teamlist.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we want to extract the logos and the team name, it turns out that both of them are enclosed by a table element followed by other multiple elements until we reach a nested image (< img >) right underneath the 'a' tag that hold the hyperlink and the text with the team's name and which subsequently holds the url source ('src') of the logo picture in the image tag. Then using the selenium and python magic that we have just learnt, we will try to find a common pattern that all the teams have so we can get them in a list and extract the features that we want from their html element. First for the team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Celtics\n",
      "Brooklyn Nets\n",
      "New York Knicks\n",
      "Philadelphia 76ers\n",
      "Toronto Raptors\n",
      "Chicago Bulls\n"
     ]
    }
   ],
   "source": [
    "team_list = driver.find_elements_by_xpath(\"//a[contains(@class, 'stats-team-list')]\")\n",
    "# Print the first 5 elements of the list\n",
    "for i, v in enumerate(team_list):\n",
    "    if i <= 5: print(v.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what have we just done???. We told the selenium driver to find all the a tags that have a class whose name contains 'stats-team-list'. And once those elements have been found, print the text that is contained in the 'a' tag. Now for the logos we can do something similar with the exception that the logo is not held in the text element of that 'img' tag but in the 'src' element. Therefore, we have to slightly modify the code so rather than extracting the text, we would take the src element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stats.nba.com/media/img/teams/logos/BOS_logo.svg\n",
      "https://stats.nba.com/media/img/teams/logos/BKN_logo.svg\n",
      "https://stats.nba.com/media/img/teams/logos/NYK_logo.svg\n",
      "https://stats.nba.com/media/img/teams/logos/PHI_logo.svg\n",
      "https://stats.nba.com/media/img/teams/logos/TOR_logo.svg\n",
      "https://stats.nba.com/media/img/teams/logos/CHI_logo.svg\n"
     ]
    }
   ],
   "source": [
    "logos = driver.find_elements_by_xpath(\"//img[contains(@class, 'team-logo')]\")\n",
    "for i, v in enumerate(logos):\n",
    "    if i <= 5: print(v.get_attribute('src'))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you just saw, given that the logos were stored in an attribute of the querying tag. We make use of the get_attribute function from selenium, so we can get the url source of each of the logos. Now in the same way that we made the dataframe out of the subparagraphs, we will do the same with the logos and teams names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logo</th>\n",
       "      <th>team_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://stats.nba.com/media/img/teams/logos/BO...</td>\n",
       "      <td>Boston Celtics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://stats.nba.com/media/img/teams/logos/BK...</td>\n",
       "      <td>Brooklyn Nets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://stats.nba.com/media/img/teams/logos/NY...</td>\n",
       "      <td>New York Knicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://stats.nba.com/media/img/teams/logos/PH...</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://stats.nba.com/media/img/teams/logos/TO...</td>\n",
       "      <td>Toronto Raptors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                logo           team_name\n",
       "0  https://stats.nba.com/media/img/teams/logos/BO...      Boston Celtics\n",
       "1  https://stats.nba.com/media/img/teams/logos/BK...       Brooklyn Nets\n",
       "2  https://stats.nba.com/media/img/teams/logos/NY...     New York Knicks\n",
       "3  https://stats.nba.com/media/img/teams/logos/PH...  Philadelphia 76ers\n",
       "4  https://stats.nba.com/media/img/teams/logos/TO...     Toronto Raptors"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logos = pd.DataFrame(columns = ['logo', 'team_name'])\n",
    "team_list = driver.find_elements_by_xpath(\"//a[contains(@class, 'stats-team-list')]\")\n",
    "# As they both have the same length, we use the counter of one to extract the other and then fill the dtframe\n",
    "for i, v in enumerate(driver.find_elements_by_xpath(\"//img[contains(@class, 'team-logo')]\")):\n",
    "    logos.loc[i, 'logo'] = v.get_attribute('src')\n",
    "    logos.loc[i, 'team_name'] = team_list[i].text\n",
    "    \n",
    "display(logos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know, I know.... you are right. These are not the logos, just a bunch of web addresses with the logos. But hey!!, if we use a little bit of html in our python notebook we can display the logo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Philadelphia 76ers</h3><img src=https://stats.nba.com/media/img/teams/logos/PHI_logo.svg style='max-height:250px;'></img>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = 3\n",
    "HTML(\"<h3>{0}</h3><img src={1} style='max-height:250px;'></img>\".format(logos.loc[team, 'team_name'], logos.loc[team, 'logo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then if we use it with an interactive widget, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2b2f3dcec440d97828274aa7a19dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Team:', options=('Boston Celtics', 'Brooklyn Nets', 'New York Knicâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.displayer(team)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def displayer(team):\n",
    "    location = logos['team_name'] == team\n",
    "    html_str = \"<h3>{0}</h3><img src={1} style='max-height:250px;'></img>\" \\\n",
    "         .format(logos.loc[location, 'team_name'].values[0], logos.loc[location, 'logo'].values[0])\n",
    "    print(\"This is the html code use to print what's below: \" + html_str)\n",
    "    return(HTML(html_str))\n",
    "    \n",
    "widget = widgets.Dropdown(\n",
    "    options= logos['team_name'],\n",
    "    value=None,\n",
    "    description='Team:')\n",
    "\n",
    "interact_manual(displayer, team = widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right next "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore how to extract the results so far of the games played in the NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
